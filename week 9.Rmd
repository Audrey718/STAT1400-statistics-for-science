---
title: "STAT1400 Statistics for Science"
subtitle: "Computer Lab Week 9"
output:
  html_document: 
    toc: true
  html_notebook: default
  pdf_document: 
    toc: true
    number_sections: yes
  word_document: 
    toc: true
# date: '`r format(Sys.time(), "%d %B %Y, %H:%M ")`'
---

```{r}
knitr::opts_chunk$set(
	echo = TRUE,
	error = FALSE,
	message = FALSE,
	comment = NA,
	prompt = FALSE,
	tidy = TRUE
)
```


# Learning Check

In this lab you should read through and run the code in the lab sheet and complete the lab assessment. 

By the end of this lab you should be able to use R to:

1. simulate outcomes of random experiments.

2. sample data from a population.

3. investigate the sampling distribution of the sample standard deviation $s$.

4. test if estimators qualify as unbiased estimators.

5. find point estimates for population parameters.


# Copyright and UWA unit content

**Is it OK to download and share course material such as lectures, unit outlines, exam papers, articles and ebooks?**

UWA is committed to providing easy access to learning material and many of your lectures are available for online access via the Lecture Capture System (LCS), accessible through the LMS. Your unit coordinator may make their lecture recordings available to download if they wish. You are allowed to access recorded lectures in the format they are supplied on the LCS – so if they are not made available to download, you must not use any software or devices to attempt to download them.

All recorded lectures and other course material, such as presentation slides, lecture and tutorial handouts, unit outlines and exam papers, are protected under the Copyright Act and remain the property of the University. You are not allowed to share these materials outside of the LMS – for example, by uploading them to study resource file sharing websites or emailing them to friends at other universities. Distributing course material outside of the LMS is a breach of the University Policy on Academic Conduct and students found to be sharing material on these sites will be penalised. University data, emails and software are also protected by copyright and should not be accessed, copied or destroyed without the permission of the copyright owner.

Other material accessible from the LMS or via the Library, such as ebooks and journal articles, are made available to you under licensing agreements that allow you to access them for personal educational use, but not to share with others.
 
**Can I share my login details?**

No! Pheme is your key to accessing a number of UWA's online services, including LMS, studentConnect, UWA email, your Library account, and Unifi. These services hold copyright material as well as your personal information, including your unit marks, enrolment information and contact details, so it is important that you do not share the access credentials with anyone else.

https://www.student.uwa.edu.au/learning/resources/ace/respect-intellectual-property/copyright-and-uwa-unit-content



Please run the following line of code for the purpose of graph quality.

```{r eval=FALSE, include=FALSE}
#Optional:
#options(repr.plot.width=4, repr.plot.height=4, repr.plot.res = 120)
```

It is necessary to define the random number generator to obtain reproducible results. You **MUST** run the command below **every time** you open your lab sheet.

```{r}
## You MUST run this code (every time you open the lab sheet).
aux <- version
if (((as.numeric(aux$major) >= 3) && (as.numeric(aux$minor) >= 6)) || (as.numeric(aux$major) >= 4)) {
  RNGkind(kind = "Mersenne-Twister", normal.kind = "Inversion", sample.kind = "Rounding")
} else {
  RNGkind(kind = "Mersenne-Twister", normal.kind = "Inversion")
}

set.seed(12345)
cat("1st check: 5 = ",sample(1:6,1),"\n",sep="")
cat("2nd check: 9 = ",ceiling(runif(1,0,10)),"\n",sep="")
cat("If the statements above are right, then it is ok.\n",sep="")
cat("\n",sep="")
cat("If you get a warning message as below, this is ok. \n   'Warning message in RNGkind(kind = ",'"',"Mersenne-Twister",'"',
    ", normal.kind = ",'"',"Inversion",'"',", :\n",'   "',"non-uniform 'Rounding' sampler used",'"',"\n",sep="")
```

We have already encountered the concept of randomness throughout the previous labs. Recall for instance how we randomly sampled from a fair die.

```{r}
roll <- sample(c(1:6), size = 11, replace = TRUE)
roll
```

If you run the code block above multiple times, it will generate different outcomes. However, recall from lecture as well as lab sheet week 8, that we can manipulate this via the `set.seed()` command as seen below. If you run the code block below multiple times now, it will always generate the same outcome.

```{r}
set.seed(12345) 
roll <- sample(c(1:6), size = 11, replace = TRUE)
roll
```

The outcome (although random) will always be the same depending on the argument of `set.seed()`. In the code above, remove $12345$ and insert a different number. Then, run the code again and see what happens. Also, try what happens when you run it multiple times.

We have hence found a way to generate random outcomes that are **replicable**. We will make use of this concept to check your assignment solutions for correctness. **The information on which** `set.seed()` **you should use is given in the assignment for each exercise**. You must follow the instruction; otherwise, you may produce a different result and get the wrong answer for the question.

## Question 1 Simulation

Simulation is the process of using a computer to mimic a physical experiment, like rolling a die for instance.

Simulation in R consist of 3 basic steps:

+ Step 1: Define the correct **sample space**.

Specify the quantity you want to simulate. For example, you might decide that you want to simulate the outcomes of rolling a fair 6-sided die.

+ Step 2: Simulate **one value** only.

Figure out how to simulate *one* value of the quantity you specified in Step 1. In our example, you have to figure out how to simulate the outcome of *one* roll of a fair die. 

+ Step 3: Decide on **how many repetitions** you would like to simulate.

Decide how many times you want to simulate the quantity. You will have to repeat Step 2 that many times. This can either directly be achieved via `size` in the `sample()` command, or via a for loop.


Below, we will now mimic rolling a fair six sided die exactly 11 times. Think about what each of the three steps outlined above looks like. Then familiarise yourself with the code.

```{r}
set.seed(1234) 
roll <- sample(c(1:6), size = 11, replace = TRUE)
roll

#set.seed(1234) 
roll_vector <- c()                      # this line creates a vector that does not have any elements yet.
for (i in 1:11) {
    roll_vector[i] <- sample(c(1:6), size = 1, replace = TRUE)       
}
roll_vector
```

Note how the two methods will yield different results despite setting the random counter. That is because we only set the random counter once at the top of the box via `set.seed(1234)`. If we set it in front of each of the methods, we will instead get the very same result for both methods as you can verify by un-commenting the second `set.seed(1234)` command.

### Exercise 1.1: monkey.bet continued

You surely remember our gambling monkey from two weeks ago throwing darts. The rules of the game were as follows:

1) if the monkey hits the panel '1', you lose 1 dollar\
2) if the monkey hits an even number nothing happens\
3) if the monkey hits an odd number between 3 and 9 (including both), you win 2 dollars\
4) if the monkey hits an odd number between 11 and 17 (including both), you win 4 dollars\
5) if the monkey hits 19, you win 10 dollars


Let's now see how well he does in earning us some money. First of all, here is the completed code for the function from last week which returns the payout for an individual throw.

```{r}
monkey.bet = function(x) {
     if (x>20 | x<1) {stop ("number is not a dart panel")}
# Returns payout if the dart lands on panel x.
    if ( x==1 ) {return (-1)}
    else if ( x%%2==0 ) {return (0)}
    else if ( x<=9 ) {return (2)}
    else if ( x<=17 ) {return (4)}
    else  {return (10) }
}
set.seed(1400)
payout <- c()
for (i in 1:10000) {
    x<- sample(1:20, size= 1, replace = TRUE, prob = rep(0.05,20))
    payout[i] <- monkey.bet(x)
}
mean(payout)
var(payout)
```

Let us now use R to simulate, so mimic, the dart-throwing monkey and the corresponding payouts 10,000 times. We will assume that the monkey hits each panel with an equal probability of 0.05. Complete the code below to achieve the 10,000 simulations.

```{r}
set.seed(1400)
payout <- c()
for (i in 1:10000) {
    x <- sample (1:20, size=1, replace = TRUE, prob = rep(0.05,20))                # needs to be completed. 
    payout[i] <- monkey.bet(x)       
}

mean(payout)
var(payout)
Ex = sum(payout*0.05)
```

* What is the average payout from these 10,000 simulations?
* What is the variance?
* What is E(X) if X was a random variable measuring the payout?
```{r}
resultm <- 0
for (i in 1:20) {
  resultm <- resultm + monkey.bet(i)/20
}
  round(resultm, 3)
```
  
  
  By capturing the results in a vector, we have given ourselves the ability to use vector methods to do computations. For example, we can use `summary.factor()` to obtain the number of times that each payout appeared. You can use the code below to check if you have completed the above code correctly. If yes, you should get:

* \$ -1: 477 times,
* \$  0: 5016 times,
* \$  2: 2022 times,
* \$  4: 1972 times,
* \$ 10:  513 times.

```{r}
summary.factor(payout)
```

### Exercise 1.2: Monopoly

In the game of "Monopoly" the amount of steps a player can move on the board is determined by the sum of two fair 6-sided dice. Follow the instructions above to simulate the amount of steps in "Monopoly". Bear in mind, that not all events in the sample space have got the same probability. Simulate the experiment 100 times. Note that the simulations are independent of another. 

```{r}
set.seed(1400) ## DO NOT REMOVE THIS LINE!
X<- 2:12
prob <- (c(1,2,3,4,5,6,5,4,3,2,1)/36)
monopoly <- sample(X, size=100, replace=T, prob=prob)
mean(monopoly)
var(monopoly)
```
```{r}
sum(x*prob)
```
```{r}
v.x <- sum(((X-e.x)^2)*prob)
cat("Population variance: ",round(
     v.x  ## Ans
    ,3),"\n",sep="")
cat("\n",sep="")
```
Once you have completed the simulation, the code below will create a visualisation of the distribution.

```{r}
counts <- table(monopoly)
barplot(counts, main="Distribution of Steps",
   xlab="results")
```

If X is a random variable measuring the sum of the two rolls:

* what is E(X)?
* what is the sample mean?
* what is Var(X)?
* what is the sample variance?

## Question 2 Simulating a Statistic

Recall from your lecture, that a **statistic** is a random value that is computed based on a sample. Hence, the sample mean is a statistic for instance. So is the sample median, the sample variance etcetera. Since the value of a statistic is based on a sample, it changes depending on the sample outcome. A statistic can therefore be regarded as a random variable and one can report its distribution, which is referred to as the "sampling distribution". Let us take a look at some sampling distributions.

### Exercise 2.1: Sampling Distribution of the Mean

Similar to last week, let us now try to find the sampling distribution of the sample mean $\bar {X}$ for the monopoly game. To do so, repeat the experiment from above 1,000 times (use a for loop for this), that is generate 1,000 samples of size 100 and calculate the mean for each of those 1,000 samples. Use the code template below to do so.
```{r}
set.seed(1400)
variance.simulated <- c() 
for (i in 1:1000) {
  monopoly <- sample(2:12, size = 100, replace = TRUE)
  variance.simulated[i] <- var(monopoly)
}
summary(variance.simulated)
```
```{r}
set.seed(1400)
vector <- c()
for (i in 1:1000) {
  monopoly <- sample(2:12, size = 100, replace = TRUE)
  vector <- mean(monopoly)
}
  summary(vector)
```


```{r}
set.seed(1400)    # DO NOT change this line.

variance.simulated <- c()     # this line creates a variable which is an empty vector. We will store the means of our 100 repitions
                  # in here as we now loop through the 'for-loop'

for(i in 1:1000){
monopoly1 <- sample(1:6, size = 100,replace = TRUE, prob = rep(1/6,6)) 
monopoly2 <- sample(1:6, size = 100, replace = TRUE,prob = rep(1/6,6))
monopoly <- monopoly1 + monopoly2
#needs to be completed. DO NOT use a for loop for the simulation!!!
mean(monopoly)
var(monopoly)# use your code from Exercise 2.1.

    means.simulated[i] <- mean(monopoly)  
    variance.simulated[i] <- var(monopoly) # stores the mean of the i-th sample of size 1000 at position i.
}
summary(means.simulated)
hist(means.simulated)
summary(variance.simulated)
hist(variance.simulated)
```
normal distribution
* What is the sample mean of $\bar X$?
* What is the sample variance of $\bar X$?
* Compare the sample variance of $X$ to the sample variance of $\bar X$. What do you notice?


Compare this to your findings from exercise 4 on labsheet week 8 and use a similar code to compare the distributions of $X$ and $\bar X$ running the block of code below.

```{r}
par(mfrow=c(1,2))
barplot(counts, main="distribution of sum",
   xlab="results") 
hist(vector,freq=TRUE,col=2, main=" distribution of mean", xlim = c(2, 12))
```

How does this visual comparison correspond to your findings regarding Var($X$) and Var($\bar X$)?

## Question 3 Sampling from a Population

First, recall from lecture the difference between the population and a sample. Now read in the "united_summer2015.csv" file. It contains information about 13,825 United Airlines domestic flights departing from San Francisco in the summer of 2015.

```{r}
united <- read.csv("summer.csv")
head(united)
nrow(united)
```

Let us now think of the 13,825 flights as the population as we did last week and draw a single random sample of size $100$ from the 'Delay' variable of that population. Study the code below and familiarise yourself with it.


```{r}
set.seed(1400)                        # DO NOT remove or change this line
united.sample <- function(x) {
  y <- sample(united$Delay, size=x, replace = F) 
  return(y)
}
united.sample(100)
```

### Exercise 3.1: Sampling Distribution of the sample standard deviation

Not only can we calculate the average delay $\bar{X}$ of our 100 sampled flights but also any other statistic we wish to investigate, say the sample standard deviation $s^2= \frac{1}{n-1}\sum_{i=1}^{n}(X_i-\bar{X})$ for instance.
Compare the sample results to the population values using the above defined function 'united.sample'

```{r}
set.seed(1400)

mean(united.sample(100))
mean(united.sample(10000))
mean(united.sample(1000))
mean(united$Delay)
```
larger than the population.

Clearly, the mean of our sample deviates from the population mean and the variance of our sample deviates from the population variance. Investigate what happens when you increase the sample size to 500 and 1000 instead. Why does this happen?

Also increase the sample size to 100,000. What happens if you try to run the code then? Why does it not work?
```{r}
set.seed(1400) 
```

```{r}
set.seed(1400)
united.sample(100)
sd(united.sample(100))  ## sample
sd(united$Delay)
# use this chunk to sample 100 times.
```

### Exercise 3.2: Histogram

To investigate and visualise (via histogram) the sampling distribution of the standard deviation, repeat the process from exercise 2.2 but for the sample standard deviation of course. Hence, generate 1,000 samples of size 100 and calculate the standard deviation for each of those 1,000 samples. Use the code box below to do so.

```{r}
# THIS CODE BLOCK WILL HAVE TO BE MANIPULATED BY YOU TO WORK!
# To do so, replace all "...j..." sections with correct code for j=1,2,3,4,5.

set.seed(1400)
list.of.sd = c()

for (i in 1:1000) {
  list.of.sd[i]<- sd(united.sample(100))
}
hist(list.of.sd)
```
```{r}
set.seed(1400)
vectorr <- c()
for (i in 1:1000) {
  vectorr[i] <- sd(united.sample(1000))
}
hist(united.sample(1000))
```

```{r}
means <- c()
for (i in 1:1000) {
  means[i] <- mean(runif(10,0,5))
}
mean(means)
```
hist(list.of.sd,  xlab = "standard deviation of delay", main = "distribution of the sample standard deviation")
```{r}
maxs <- c()
for (i in 1:1000) {
  maxs[i] <- max(runif(10,0,5))
}
mean(maxs)
```
```{r}
maxmins <- c()
for (i in 1:1000) {
  maxmins <- max(runif(10,0,5))/2 + min(runif(10,0,5))/2
}
mean(maxmins)
```
```{r}
set.seed(1400)
our_sample = united[sample(nrow(united), size = 1000, replace = F),]
max(length(our_sample))
```










          * What does the histogram look like?
          
          * Is it symmetric or skewed?
          
          * In which interval do you find most of your sample standard deviations?

## Question 4 Point Estimation for a Population Parameter

In inferential statistics we are more interested in making reasonable assertions about the population (population parameters) rather than the sample. A first, very basic approach is to find a point estimate of the parameter of interest, say the population mean, based on a sample. A classic and solid approach to point estimate the population mean is to calculate the sample mean and take that value as a point estimation. We have calculated sample means many times throughout this lab and discovered that they get closer to the population mean as the sample size increases. Essentially you can assume those estimates to be "good" guesses of the population mean, sometimes also referred to as the "true mean". 

However, there are many potential other ways how we could derive a point estimate for the population mean based on a sample. Instead of taking the sample mean, we could for instance take our smallest observation or the biggest observation or the average of those two instead. Think about why these three estimators aren't "good" and also think about how you would point estimate other population parameters like variance and median, if it was up to you. 

### Exercise 4.1: Unbiased Point Estimator for the Population Mean

Whether an estimator qualifies as a "good" estimator is generally beyond the scope of this unit, but one of the main characteristics an estimator should have to be considered a "good" estimator is being unbiased.

Definition: An estimator $\hat{\theta}$ is unbiased if its expectation value equals the parameter it seeks to estimate, that is if $E(\hat{\theta}) = \theta$, where $\theta$ denotes the true parameter value  $\hat{\theta}$ seeks to estimate.

Example: Let $X_1,X_2,...,X_n$ be $n$ random variables with $E(X_i)=\mu$ for all $i\in\{1,...n\}$. Then, we can manually compute the expectation of the sample mean and thereby prove that the sample mean **$\bar{X}$ is indeed an unbiased estimator for the population mean $\mu$, regardless of the sample size $n$, since**:

$E(\bar{X})= E(\frac{1}{n}\sum_{i=1}^{n}X_i)= \frac{1}{n}\sum_{i=1}^{n}E(X_i)= \frac{1}{n}\sum_{i=1}^{n}\mu= \frac{1}{n}n\mu=\mu$

**This result is true regardless of the distribution of the $X_i$'s.**

For example, let the $X_i$'s follow a uniform distribution between 0 and 5; we then know $E(X_i)=2.5$, i.e. the true mean $\mu=2.5$. And by the proof above, we also know $E(\bar{X})=2.5$ regardless of the sample size $n$. Also use the following lines of code to further help illustrate this. Try the following separately:

1) increase the number of averages you simulate from 100 to 1,000, to 10,000 and 100,000. What do you notice?\
$->$ This demonstrates the unbiasedness.

2) decrease the sample size $n$ from 10 to 5, to 3 and even 1.\
$->$ This demonstrates that the unbiasedness is independent of the sample size.







```{r}
means <- c()
for(i in 1:100000){
    means[i] <- mean(runif(10,0,5))
}
mean(means)
```
close to 2.5
### Exercise 4.2: Test unbiasedness via simulation

However, for most statistics it is much harder to derive the expected value. For example, to compute $E(max\{X_1,...,X_n\})$ we would need to know the distribution of the random variable $X_{max}=max\{X_1,...,X_n\}$, which is beyond the scope of this unit. 
But, we can use a simulation approach similar to the one above to figure out if $X_{max}$ is also an unbiased estimator for the sample mean. Study the code below, which helps us answer this question.

```{r}
maxs <- c()
for(i in 1:100){
    maxs[i] <- max(runif(10,0,5))
}
mean(maxs)
```
```{r}
mins <- c()
for(i in 1:100){
    mins[i] <- min(runif(10,0,5))
}
mean(mins)
```
```{r}
(mean(mins) + mean(maxs))/2
```



Based on your simulation, do you think that $X_{max}$ is an unbiased estimator for the true mean $\mu$=2.5? Try similar simulations to also find out if:

* $X_{max}$ is an unbiased estimator for the true maximum value 5.
* $X_{min}=min\{X_1,...,X_n\}$ is an unbiased estimator for the true minimum value 0.
* $(X_{max}+X_{min})/2$ is an unbiased estimator for the true mean.

### Exercise 4.3 Your independent exercise

Now, let us derive some point estimates for population parameters of the flight delays from above **via their sample equivalents** using R.

For the purpose of this exercise, use set.seed(1400) to set the random counter. 

Find point estimates for the following parameters by using their sample equivalents based on samples of size 100.

        - The true variance sigma squared. 

        - The true proportion of flights that have at least 20 minutes delay. 

        - The true biggest delay. 


```{r}
set.seed(1400)# DO NOT delete this line!!!

# choosing a sample of size 1000 from the above dataframe and calling it "our_sample". 
# ATTENTION: At this point we are sampling rows of the dataframe, not values yet.
our_sample = united[sample(nrow(united), size = 1000, replace = F), ]

# calculating the sample mean of 'Delay' in "our_sample" as a point estimate for the population mean.
mean(our_sample$Delay)

#use this space here to derive the output needed for your assignment!

# 1) Find a point estimate for the true variance

# 2) ...

# 3) ...

```

